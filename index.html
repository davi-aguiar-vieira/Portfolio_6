
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.45">
    
    
      
        <title>IA</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#portfolio-6" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="." title="IA" class="md-header__button md-logo" aria-label="IA" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            IA
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Portfólio 6
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="." class="md-tabs__link">
        
  
    
  
  Portfólio 6

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="IA" class="md-nav__button md-logo" aria-label="IA" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    IA
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="." class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Portfólio 6
  </span>
  

      </a>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="portfolio-6">Portfólio 6</h1>
<h1 id="aprendizado-de-maquina"><strong>Aprendizado de Máquina</strong></h1>
<p>O aprendizado de máquina (Machine Learning - ML) é um subcampo da inteligência artificial que permite que sistemas computacionais aprendam padrões a partir de dados e realizem previsões ou classificações sem serem explicitamente programados para isso. Esse processo ocorre por meio de algoritmos que ajustam seus parâmetros com base em experiências anteriores, tornando-se cada vez mais eficientes na realização de tarefas específicas.</p>
<p>A popularização do aprendizado de máquina se deve ao crescimento exponencial na disponibilidade de dados, ao aumento da capacidade computacional e ao desenvolvimento de algoritmos avançados que possibilitam extrair insights valiosos a partir de grandes volumes de informação. Sua aplicação se estende a diversas áreas, incluindo saúde, finanças, transporte, segurança cibernética, entre outras.</p>
<p>Os algoritmos de aprendizado de máquina são geralmente categorizados em três principais tipos de aprendizado: supervisionado, não supervisionado e por reforço. No aprendizado supervisionado, os modelos são treinados com dados rotulados, onde a saída correta é previamente conhecida. Já no aprendizado não supervisionado, os algoritmos identificam padrões ocultos nos dados sem a necessidade de rótulos. O aprendizado por reforço, por sua vez, utiliza um sistema de recompensa para guiar o modelo na tomada de decisões.</p>
<p>O estudo e aplicação do aprendizado de máquina envolvem diversas técnicas e desafios, como a escolha adequada de algoritmos, a extração de características dos dados, o pré-processamento das informações e o tratamento de problemas como overfitting e underfitting. Além disso, a interpretabilidade dos modelos, por meio de abordagens de inteligência artificial explicável (XAI), tem sido cada vez mais relevante para garantir transparência e confiabilidade nas decisões automatizadas.</p>
<p>Nos próximos tópicos, exploraremos em detalhes os diferentes tipos de aprendizado de máquina, as técnicas utilizadas em classificação e regressão, os principais algoritmos empregados e o impacto das redes neurais e do aprendizado profundo no avanço dessa área.</p>
<h1 id="tipos-de-aprendizado-de-maquina"><strong>Tipos de Aprendizado de Máquina</strong></h1>
<p>O aprendizado de máquina pode ser dividido em três categorias principais: aprendizado supervisionado, aprendizado não supervisionado e aprendizado por reforço. Cada um desses tipos possui características distintas e é aplicado de acordo com a natureza dos dados e o objetivo do modelo.</p>
<h3 id="aprendizado-supervisionado">Aprendizado Supervisionado</h3>
<p>O aprendizado supervisionado é um dos métodos mais comuns e eficazes de aprendizado de máquina. Ele se baseia no uso de um conjunto de dados rotulado, onde cada entrada possui uma saída associada. O modelo é treinado para reconhecer padrões e prever corretamente as respostas com base nos exemplos apresentados durante o treinamento.</p>
<p>Os algoritmos de aprendizado supervisionado podem ser divididos em dois tipos principais: classificação e regressão. Na classificação, o objetivo é categorizar os dados em classes predefinidas, como identificar se um e-mail é spam ou não. Já na regressão, o objetivo é prever valores contínuos, como o preço de um imóvel com base em suas características.</p>
<p>A seguir, um exemplo de aprendizado supervisionado utilizando Regressão Linear com a biblioteca scikit-learn. O código cria um conjunto de dados fictício, treina um modelo de regressão linear e plota os resultados para visualizar a relação entre as variáveis.</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# Gerando dados fictícios
np.random.seed(0)
x = 10 * np.random.rand(100, 1)
y = 2.5 * x + np.random.randn(100, 1) * 2  # Relação linear com ruído

# Dividindo os dados em treino e teste
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

# Criando e treinando o modelo de Regressão Linear
modelo = LinearRegression()
modelo.fit(x_train, y_train)

# Fazendo previsões
y_pred = modelo.predict(x_test)

# Plotando os resultados
plt.scatter(x_test, y_test, color='blue', label='Dados reais')
plt.plot(x_test, y_pred, color='red', linewidth=2, label='Regressão Linear')
plt.xlabel('Variável de entrada (x)')
plt.ylabel('Variável de saída (y)')
plt.legend()
plt.title('Exemplo de Regressão Linear')
plt.show()
</code></pre>
<p><img alt="Aprendizado Supervisionado" src="supervisionado.png" /></p>
<h3 id="aprendizado-nao-supervisionado">Aprendizado Não Supervisionado</h3>
<p>No aprendizado não supervisionado, os dados utilizados para o treinamento não possuem rótulos predefinidos. O objetivo desse tipo de aprendizado é identificar padrões e estruturas ocultas nos dados, agrupando informações similares sem uma categorização prévia.</p>
<p>Os principais algoritmos de aprendizado não supervisionado incluem métodos como o K-Means Clustering, que agrupa dados semelhantes em clusters, e Self-Organizing Maps (SOM), que mapeiam padrões de alto nível nos dados. Esse tipo de aprendizado é amplamente utilizado em áreas como segmentação de clientes, análise de anomalias e compressão de dados.</p>
<p>Abaixo um exemplo de <strong>Aprendizado Não Supervisionado</strong> usando o algoritmo <strong>K-Means Clustering</strong>. Esse código gera dados fictícios, aplica o K-Means para agrupar os dados em clusters e plota o resultado.  </p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Gerando dados fictícios para agrupamento
np.random.seed(0)
X = np.concatenate([
    np.random.randn(50, 2) + [2, 2],  # Cluster 1
    np.random.randn(50, 2) + [8, 8],  # Cluster 2
    np.random.randn(50, 2) + [2, 8]   # Cluster 3
])

# Aplicando K-Means para encontrar 3 clusters
kmeans = KMeans(n_clusters=3, random_state=0, n_init=10)
kmeans.fit(X)
labels = kmeans.labels_
centroids = kmeans.cluster_centers_

# Plotando os dados e os centróides dos clusters
plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolors='k', label=&quot;Pontos de dados&quot;)
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label=&quot;Centroides&quot;)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Exemplo de K-Means Clustering')
plt.legend()
plt.show()
</code></pre>
<p><img alt="Aprendizado Não Supervisionado" src="nao_supervisionado.png" /></p>
<p><strong>Explicação:</strong>
1. Geramos dados distribuídos em três grupos distintos.
2. Aplicamos o <strong>K-Means</strong> para encontrar três clusters nos dados.
3. Plotamos os pontos com cores representando seus clusters e marcamos os centróides em <strong>vermelho</strong>.</p>
<p>Este exemplo ilustra como o K-Means pode encontrar padrões sem supervisão e é útil para aplicações como <strong>segmentação de clientes</strong> ou <strong>detecção de padrões</strong>.</p>
<h3 id="aprendizado-por-reforco">Aprendizado por Reforço</h3>
<p>O aprendizado por reforço difere dos outros dois tipos por ser baseado em um sistema de recompensas e penalidades. Nesse modelo, um agente interage com um ambiente e aprende a tomar decisões para maximizar uma recompensa acumulada ao longo do tempo.</p>
<p>Esse tipo de aprendizado é frequentemente utilizado em robótica, jogos e sistemas de controle, onde o agente precisa aprender a executar tarefas complexas sem um conjunto de regras predefinido. Um dos algoritmos mais conhecidos nessa categoria é o Q-Learning, que permite que o agente aprenda políticas ótimas de decisão explorando diferentes ações e observando seus efeitos.</p>
<p>Cada um desses tipos de aprendizado tem aplicações específicas e desempenha um papel crucial no avanço da inteligência artificial, permitindo o desenvolvimento de sistemas mais eficientes e adaptáveis às necessidades do mundo real.</p>
<p>Abaixo um exemplo de <strong>Aprendizado por Reforço</strong> usando o algoritmo <strong>Q-Learning</strong> para ensinar um agente a navegar em um ambiente de grid (labirinto). O código inclui a simulação do agente aprendendo a sair de um ponto inicial até um objetivo, além de um gráfico que mostra a evolução das recompensas ao longo do treinamento.</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Configuração do ambiente (grid 5x5)
size = 5
num_states = size * size
num_actions = 4  # [0: cima, 1: baixo, 2: esquerda, 3: direita]
goal_state = num_states - 1  # Última célula do grid como objetivo

# Inicialização da Q-table
q_table = np.zeros((num_states, num_actions))
learning_rate = 0.1
discount_factor = 0.9
exploration_rate = 1.0
exploration_decay = 0.995
num_episodes = 500

# Função para converter estado em coordenadas (linha, coluna)
def state_to_coord(state):
    return state // size, state % size

# Função para converter coordenadas em estado
def coord_to_state(row, col):
    return row * size + col

# Função para tomar uma ação no ambiente e obter o próximo estado e recompensa
def step(state, action):
    row, col = state_to_coord(state)
    if action == 0 and row &gt; 0: row -= 1  # Cima
    elif action == 1 and row &lt; size - 1: row += 1  # Baixo
    elif action == 2 and col &gt; 0: col -= 1  # Esquerda
    elif action == 3 and col &lt; size - 1: col += 1  # Direita
    next_state = coord_to_state(row, col)
    reward = 1 if next_state == goal_state else -0.01  # Recompensa apenas na meta
    return next_state, reward

# Treinamento do agente usando Q-Learning
rewards_per_episode = []
for episode in range(num_episodes):
    state = 0  # Estado inicial (canto superior esquerdo)
    total_reward = 0

    while state != goal_state:
        # Escolher ação com exploração/explicação
        if np.random.rand() &lt; exploration_rate:
            action = np.random.choice(num_actions)  # Escolha aleatória (exploração)
        else:
            action = np.argmax(q_table[state])  # Melhor ação conhecida (exploração)

        next_state, reward = step(state, action)
        total_reward += reward

        # Atualizar Q-table
        best_next_action = np.max(q_table[next_state])
        q_table[state, action] += learning_rate * (reward + discount_factor * best_next_action - q_table[state, action])

        state = next_state

    rewards_per_episode.append(total_reward)
    exploration_rate *= exploration_decay  # Decaimento da exploração

# Plotando a evolução da recompensa por episódio
plt.figure(figsize=(8, 5))
plt.plot(rewards_per_episode, label=&quot;Recompensa por Episódio&quot;)
plt.xlabel(&quot;Episódios&quot;)
plt.ylabel(&quot;Recompensa Acumulada&quot;)
plt.title(&quot;Aprendizado por Reforço com Q-Learning&quot;)
plt.legend()
plt.show()
</code></pre>
<p><img alt="Reforço" src="reforco.png" /></p>
<p><strong>Explicação:</strong>
1. Criamos um <strong>grid 5x5</strong> onde o agente começa no canto superior esquerdo (estado 0) e precisa alcançar a célula inferior direita (estado final).
2. Implementamos o <strong>Q-Learning</strong>, onde o agente aprende tomando ações e atualizando sua <strong>Q-table</strong>.
3. O agente explora aleatoriamente no início e gradualmente passa a explorar menos (exploration decay).
4. No final, plotamos um gráfico mostrando a evolução das recompensas ao longo dos episódios.</p>
<p>Este código demonstra um exemplo básico de <strong>aprendizado por reforço</strong> e pode ser expandido para ambientes mais complexos, como jogos ou robótica.</p>
<h1 id="algoritmos-de-aprendizado-supervisionado"><strong>Algoritmos de Aprendizado Supervisionado</strong></h1>
<h2 id="1-k-nearest-neighbors-knn"><strong>1. K-Nearest Neighbors (KNN)</strong></h2>
<h3 id="o-que-e-o-knn"><strong>O que é o KNN?</strong></h3>
<p>O algoritmo <strong>K-Nearest Neighbors</strong> (KNN) é um método simples e intuitivo para <strong>classificação e regressão</strong>. Ele se baseia no princípio de que <strong>pontos de dados semelhantes geralmente estão próximos uns dos outros</strong>. Assim, para classificar um novo ponto, o KNN verifica quais são seus <strong>K vizinhos mais próximos</strong> e decide sua categoria com base na maioria dos vizinhos.  </p>
<h3 id="funcionamento-do-knn"><strong>Funcionamento do KNN:</strong></h3>
<ol>
<li>Definir um valor para <strong>K</strong> (quantidade de vizinhos a serem considerados).  </li>
<li>Calcular a distância entre o novo dado e todos os pontos do conjunto de treinamento.  </li>
<li>Selecionar os <strong>K pontos mais próximos</strong>.  </li>
<li>Para classificação: atribuir a classe mais frequente entre os vizinhos.  </li>
<li>Para regressão: calcular a média dos valores dos vizinhos.  </li>
</ol>
<h3 id="principais-caracteristicas"><strong>Principais características:</strong></h3>
<ul>
<li><strong>Simples de entender e implementar.</strong>  </li>
<li><strong>Não precisa de treinamento explícito</strong>, pois apenas armazena os dados e realiza os cálculos no momento da predição.  </li>
<li><strong>Desempenho pode ser afetado por dados ruidosos e alta dimensionalidade.</strong>  </li>
</ul>
<h3 id="aplicacoes"><strong>Aplicações:</strong></h3>
<ul>
<li><strong>Reconhecimento de padrões</strong>, como identificação de manuscritos.  </li>
<li><strong>Sistemas de recomendação</strong>, agrupando usuários com interesses semelhantes.  </li>
<li><strong>Classificação de doenças</strong>, analisando sintomas de pacientes.  </li>
</ul>
<h3 id="desafios-do-knn"><strong>Desafios do KNN:</strong></h3>
<ul>
<li><strong>Lento para grandes volumes de dados</strong>, pois precisa calcular distâncias para todos os pontos do conjunto de treinamento.  </li>
<li><strong>Escolha do K ideal</strong> pode afetar a precisão (valores pequenos tornam o modelo sensível a ruídos, valores grandes podem perder detalhes).  </li>
</ul>
<hr />
<h2 id="2-modelos-lineares"><strong>2. Modelos Lineares</strong></h2>
<p>Os <strong>modelos lineares</strong> são uma abordagem clássica no aprendizado de máquina supervisionado, baseando-se na suposição de que há uma <strong>relação linear entre as variáveis de entrada e a saída</strong>. Eles podem ser usados tanto para <strong>regressão</strong> quanto para <strong>classificação</strong>.  </p>
<h3 id="21-regressao-linear"><strong>2.1 Regressão Linear</strong></h3>
<p>A <strong>Regressão Linear</strong> tenta encontrar uma reta que melhor se ajuste aos dados, minimizando o erro entre as previsões e os valores reais. A equação geral de um modelo linear é:  </p>
<div class="arithmatex">\[
Y = W_1 X_1 + W_2 X_2 + ... + W_n X_n + b
\]</div>
<p>Onde:<br />
- <span class="arithmatex">\( Y \)</span> é a variável dependente (previsão).<br />
- <span class="arithmatex">\( X_1, X_2, ..., X_n \)</span> são as variáveis de entrada.<br />
- <span class="arithmatex">\( W_1, W_2, ..., W_n \)</span> são os pesos (coeficientes do modelo).<br />
- <span class="arithmatex">\( b \)</span> é o termo de viés (bias).  </p>
<h3 id="aplicacoes-da-regressao-linear"><strong>Aplicações da Regressão Linear:</strong></h3>
<ul>
<li><strong>Previsão de preços de imóveis.</strong>  </li>
<li><strong>Estimativa de vendas de produtos.</strong>  </li>
<li><strong>Modelagem de relações econômicas.</strong>  </li>
</ul>
<h3 id="22-regressao-logistica"><strong>2.2 Regressão Logística</strong></h3>
<p>A <strong>Regressão Logística</strong> é usada para <strong>problemas de classificação binária</strong>, como prever se um e-mail é <strong>spam ou não spam</strong>. Em vez de uma reta, a regressão logística usa uma função sigmoide para transformar valores contínuos em probabilidades.  </p>
<p>A equação da regressão logística é:  </p>
<div class="arithmatex">\[
P(Y=1) = \frac{1}{1 + e^{-(W_1X_1 + W_2X_2 + ... + W_nX_n + b)}}
\]</div>
<p>Se a probabilidade for maior que um certo limiar (como <strong>0.5</strong>), o modelo classifica o exemplo como <strong>1</strong>, caso contrário, como <strong>0</strong>.  </p>
<h3 id="vantagens-dos-modelos-lineares"><strong>Vantagens dos Modelos Lineares:</strong></h3>
<ul>
<li><strong>Fáceis de interpretar e implementar.</strong>  </li>
<li><strong>Funcionam bem com dados estruturados e de baixa dimensionalidade.</strong>  </li>
<li><strong>Rápidos para treinar e prever.</strong>  </li>
</ul>
<h3 id="desvantagens"><strong>Desvantagens:</strong></h3>
<ul>
<li><strong>Não capturam relações não lineares nos dados.</strong>  </li>
<li><strong>Sensíveis a outliers</strong>, que podem distorcer os resultados.  </li>
<li><strong>Podem ter baixa performance em problemas complexos.</strong>  </li>
</ul>
<hr />
<h2 id="3-classificadores-bayesianos"><strong>3. Classificadores Bayesianos</strong></h2>
<p>Os <strong>classificadores bayesianos</strong> são baseados no <strong>Teorema de Bayes</strong>, que expressa a relação entre probabilidades condicionais. Eles são particularmente úteis quando queremos fazer previsões baseadas em distribuições estatísticas de dados.  </p>
<h3 id="31-teorema-de-bayes"><strong>3.1 Teorema de Bayes</strong></h3>
<p>O Teorema de Bayes define a probabilidade de um evento <span class="arithmatex">\( A \)</span> ocorrer, dado que outro evento <span class="arithmatex">\( B \)</span> já ocorreu:</p>
<div class="arithmatex">\[
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
\]</div>
<p>Onde:<br />
- <span class="arithmatex">\( P(A|B) \)</span> é a probabilidade de <strong>A</strong> dado <strong>B</strong> (probabilidade posterior).<br />
- <span class="arithmatex">\( P(B|A) \)</span> é a probabilidade de <strong>B</strong> dado <strong>A</strong>.<br />
- <span class="arithmatex">\( P(A) \)</span> e <span class="arithmatex">\( P(B) \)</span> são probabilidades independentes dos eventos.  </p>
<h3 id="32-naive-bayes"><strong>3.2 Naive Bayes</strong></h3>
<p>O <strong>Naive Bayes</strong> é um dos classificadores mais usados e assume que as características dos dados são <strong>independentes entre si</strong>. Isso permite cálculos mais rápidos e eficientes.  </p>
<h3 id="vantagens-do-naive-bayes"><strong>Vantagens do Naive Bayes:</strong></h3>
<ul>
<li><strong>Funciona bem com grandes conjuntos de dados.</strong>  </li>
<li><strong>Eficiente para texto e problemas de NLP (Processamento de Linguagem Natural).</strong>  </li>
<li><strong>Treinamento rápido, pois usa apenas probabilidades.</strong>  </li>
</ul>
<h3 id="desvantagens_1"><strong>Desvantagens:</strong></h3>
<ul>
<li><strong>A suposição de independência das características pode ser irrealista em alguns casos.</strong>  </li>
<li><strong>Desempenho inferior em problemas complexos onde as variáveis são fortemente correlacionadas.</strong>  </li>
</ul>
<h3 id="aplicacoes-do-naive-bayes"><strong>Aplicações do Naive Bayes:</strong></h3>
<ul>
<li><strong>Classificação de e-mails (Spam vs. Não Spam).</strong>  </li>
<li><strong>Análise de sentimentos em textos.</strong>  </li>
<li><strong>Diagnóstico médico baseado em sintomas.</strong></li>
</ul>
<h1 id="algoritmos-de-aprendizado-nao-supervisionado"><strong>Algoritmos de Aprendizado Não Supervisionado</strong></h1>
<p>O <strong>aprendizado não supervisionado</strong> é uma abordagem da inteligência artificial em que o modelo aprende <strong>padrões e estruturas nos dados sem rótulos pré-definidos</strong>. Ao contrário do aprendizado supervisionado, onde há um conjunto de dados com entradas e saídas conhecidas, no aprendizado não supervisionado o algoritmo deve identificar padrões por conta própria.  </p>
<p>Dois dos algoritmos mais importantes dentro dessa abordagem são o <strong>K-means Clustering</strong>, utilizado para agrupamento de dados, e o <strong>Self-Organizing Maps (SOM)</strong>, uma técnica baseada em redes neurais que ajuda na visualização de dados de alta dimensão.  </p>
<hr />
<h2 id="1-k-means-clustering"><strong>1. K-means Clustering</strong></h2>
<p>O <strong>K-means</strong> é um dos algoritmos mais populares de agrupamento (<em>clustering</em>). Ele funciona <strong>dividindo um conjunto de dados em K grupos distintos</strong>, onde <strong>K</strong> é um número escolhido previamente pelo usuário. O objetivo do algoritmo é minimizar a variabilidade dentro de cada grupo, garantindo que os pontos dentro de um mesmo cluster sejam semelhantes entre si e diferentes dos pontos em outros clusters.  </p>
<h3 id="11-como-funciona-o-k-means"><strong>1.1 Como funciona o K-means?</strong></h3>
<p>O K-means segue um processo iterativo para encontrar os melhores agrupamentos nos dados:  </p>
<ol>
<li><strong>Escolha do número de clusters (K):</strong> o usuário define quantos grupos deseja encontrar.  </li>
<li><strong>Inicialização dos centróides:</strong> K pontos iniciais são escolhidos aleatoriamente como os "centros" dos grupos.  </li>
<li><strong>Atribuição de pontos aos clusters:</strong> cada ponto do conjunto de dados é atribuído ao centróide mais próximo.  </li>
<li><strong>Atualização dos centróides:</strong> os centróides são recalculados como a média dos pontos atribuídos a cada cluster.  </li>
<li><strong>Repetição do processo:</strong> os passos 3 e 4 se repetem até que os centróides não mudem mais ou um critério de parada seja atingido.  </li>
</ol>
<h3 id="12-aplicacoes-do-k-means"><strong>1.2 Aplicações do K-means</strong></h3>
<p>O K-means é amplamente utilizado em diversas áreas, como:  </p>
<ul>
<li><strong>Segmentação de clientes:</strong> agrupar consumidores com base em padrões de compra.  </li>
<li><strong>Compressão de imagens:</strong> reduzir cores em uma imagem agrupando pixels semelhantes.  </li>
<li><strong>Agrupamento de documentos:</strong> organizar textos similares para análise de tópicos.  </li>
<li><strong>Detecção de anomalias:</strong> encontrar padrões diferentes dentro de um conjunto de dados.  </li>
</ul>
<h3 id="13-vantagens-e-desvantagens"><strong>1.3 Vantagens e Desvantagens</strong></h3>
<p><strong>Vantagens:</strong><br />
- Simples e fácil de implementar.<br />
- Rápido para conjuntos de dados médios e grandes.<br />
- Pode ser utilizado em diferentes tipos de aplicações.  </p>
<p><strong>Desvantagens:</strong><br />
- O número de clusters K deve ser definido previamente, o que pode ser difícil sem conhecimento prévio dos dados.<br />
- Pode convergir para soluções locais (a escolha inicial dos centróides pode afetar o resultado).<br />
- Não funciona bem com dados que tenham formas de clusters não esféricas.  </p>
<hr />
<h2 id="2-self-organizing-maps-som-mapas-auto-organizaveis"><strong>2. Self-Organizing Maps (SOM - Mapas Auto-organizáveis)</strong></h2>
<p>O <strong>Self-Organizing Map (SOM)</strong>, ou <strong>Mapa Auto-organizável de Kohonen</strong>, é um tipo especial de <strong>rede neural artificial não supervisionada</strong> que aprende <strong>representações de dados de alta dimensão</strong> em um espaço de menor dimensão, geralmente <strong>duas dimensões</strong>. Ele é amplamente usado para <strong>visualizar dados complexos e identificar padrões ocultos</strong>.  </p>
<h3 id="21-como-funciona-o-som"><strong>2.1 Como funciona o SOM?</strong></h3>
<p>O SOM funciona distribuindo os dados em uma grade organizada de neurônios, onde cada neurônio representa um grupo de características semelhantes. O treinamento é feito de maneira iterativa, seguindo os seguintes passos:  </p>
<ol>
<li><strong>Inicialização:</strong> cria-se uma grade de neurônios com pesos aleatórios.  </li>
<li><strong>Escolha de um ponto de dados:</strong> um exemplo é escolhido aleatoriamente do conjunto de dados.  </li>
<li><strong>Busca do neurônio vencedor:</strong> o neurônio mais próximo do ponto de dados é identificado como <strong>Best Matching Unit (BMU)</strong>.  </li>
<li><strong>Ajuste dos pesos:</strong> os pesos do BMU e de seus neurônios vizinhos são atualizados para se parecerem mais com o exemplo escolhido.  </li>
<li><strong>Repetição do processo:</strong> os passos 2 a 4 são repetidos até que o mapa esteja treinado.  </li>
</ol>
<h3 id="22-aplicacoes-do-som"><strong>2.2 Aplicações do SOM</strong></h3>
<p>O SOM é amplamente utilizado para <strong>reduzir a dimensionalidade</strong> e <strong>explorar visualmente dados complexos</strong>. Algumas aplicações incluem:  </p>
<ul>
<li><strong>Visualização de dados:</strong> transformar dados de alta dimensão em mapas 2D compreensíveis.  </li>
<li><strong>Reconhecimento de padrões:</strong> usado em diagnósticos médicos para identificar padrões em exames.  </li>
<li><strong>Análise de clientes:</strong> usado no marketing para encontrar segmentos de consumidores.  </li>
<li><strong>Agrupamento de genes:</strong> aplicado na biologia para organizar genes com funções semelhantes.  </li>
</ul>
<h3 id="23-vantagens-e-desvantagens"><strong>2.3 Vantagens e Desvantagens</strong></h3>
<p><strong>Vantagens:</strong><br />
- Muito útil para visualizar dados complexos em duas dimensões.<br />
- Permite encontrar relações ocultas nos dados sem necessidade de rótulos.<br />
- Flexível e pode ser aplicado em diversos contextos.  </p>
<p><strong>Desvantagens:</strong><br />
- O treinamento pode ser demorado para grandes volumes de dados.<br />
- Os resultados podem ser difíceis de interpretar sem conhecimento especializado.<br />
- A escolha do tamanho da grade afeta o desempenho do modelo.  </p>
<hr />
<h2 id="3-comparacao-entre-k-means-e-som"><strong>3. Comparação entre K-means e SOM</strong></h2>
<table>
<thead>
<tr>
<th>Característica</th>
<th>K-means Clustering</th>
<th>Self-Organizing Maps (SOM)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tipo de Algoritmo</td>
<td>Agrupamento</td>
<td>Rede Neural Não Supervisionada</td>
</tr>
<tr>
<td>Entrada de Dados</td>
<td>Dados numéricos</td>
<td>Dados numéricos e de alta dimensão</td>
</tr>
<tr>
<td>Saída</td>
<td>K grupos distintos</td>
<td>Mapa organizado de neurônios</td>
</tr>
<tr>
<td>Interpretação</td>
<td>Simples, cada ponto pertence a um cluster</td>
<td>Complexa, os dados são distribuídos em uma grade</td>
</tr>
<tr>
<td>Aplicações</td>
<td>Segmentação de clientes, compressão de imagens, agrupamento de documentos</td>
<td>Visualização de dados, reconhecimento de padrões, análise de clientes</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="conclusao"><strong>Conclusão</strong></h2>
<p>Os algoritmos de aprendizado não supervisionado, como <strong>K-means Clustering e Self-Organizing Maps (SOM)</strong>, são essenciais para explorar grandes volumes de dados sem rótulos.  </p>
<ul>
<li>O <strong>K-means Clustering</strong> é simples e eficiente para encontrar grupos em dados, mas exige a definição prévia do número de clusters.  </li>
<li>O <strong>Self-Organizing Map (SOM)</strong> é uma poderosa ferramenta para visualizar e organizar dados complexos, embora seu treinamento possa ser mais difícil de interpretar.  </li>
</ul>
<h1 id="aprendizado-por-reforco-e-q-learning"><strong>Aprendizado por Reforço e Q-Learning</strong></h1>
<h2 id="q-learning-aprendizado-de-valores"><strong>Q-Learning: Aprendizado de Valores</strong></h2>
<p>O <strong>Q-Learning</strong> é um dos algoritmos mais populares de aprendizado por reforço. Ele pertence à categoria de <strong>aprendizado de valores</strong>, ou seja, busca encontrar a <strong>função de valor de ação</strong> que informa ao agente qual é a melhor ação a ser tomada em cada estado.  </p>
<p>A ideia central do Q-Learning é armazenar um conjunto de valores conhecidos como <strong>Q-values</strong>, que representam a "qualidade" de uma ação em determinado estado. Esses valores são atualizados ao longo do tempo por meio da seguinte equação de aprendizado:  </p>
<div class="arithmatex">\[
Q(s, a) \leftarrow Q(s, a) + \alpha \left[ R + \gamma \max_{a'} Q(s', a') - Q(s, a) \right]
\]</div>
<p>Onde:  </p>
<ul>
<li><strong><span class="arithmatex">\( Q(s, a) \)</span></strong> → Valor Q para um estado <span class="arithmatex">\( s \)</span> e uma ação <span class="arithmatex">\( a \)</span>.  </li>
<li><strong><span class="arithmatex">\( \alpha \)</span></strong> → Taxa de aprendizado (determina o quão rápido o agente se adapta).  </li>
<li><strong><span class="arithmatex">\( R \)</span></strong> → Recompensa recebida após realizar a ação <span class="arithmatex">\( a \)</span> no estado <span class="arithmatex">\( s \)</span>.  </li>
<li><strong><span class="arithmatex">\( \gamma \)</span></strong> → Fator de desconto (determina o peso das recompensas futuras).  </li>
<li><strong><span class="arithmatex">\( \max_{a'} Q(s', a') \)</span></strong> → Melhor valor Q esperado no próximo estado <span class="arithmatex">\( s' \)</span>.  </li>
</ul>
<h3 id="como-o-q-learning-funciona"><strong>Como o Q-Learning Funciona?</strong></h3>
<ol>
<li><strong>Inicialização</strong>: O agente cria uma <strong>tabela Q (Q-table)</strong>, geralmente preenchida com zeros.  </li>
<li><strong>Exploração e Exploração</strong>:  </li>
<li>O agente <strong>explora</strong> o ambiente escolhendo ações aleatórias para aprender.  </li>
<li>O agente <strong>explora</strong> ações que já conhece para maximizar a recompensa.  </li>
<li><strong>Atualização da Q-Table</strong>: Com base nas recompensas recebidas, o agente ajusta seus valores Q.  </li>
<li><strong>Repetição</strong>: O processo se repete até que o agente aprenda a melhor política de decisão.  </li>
</ol>
<hr />
<h2 id="aplicacoes-do-q-learning"><strong>Aplicações do Q-Learning</strong></h2>
<p>O algoritmo Q-Learning é amplamente utilizado em diversas áreas, incluindo:  </p>
<h3 id="31-jogos-e-inteligencia-artificial"><strong>3.1 Jogos e Inteligência Artificial</strong></h3>
<ul>
<li>Ensinar <strong>robôs de jogos</strong> a tomar decisões estratégicas (como no xadrez e no Go).  </li>
<li>Criar <strong>agentes autônomos</strong> em videogames que aprendem a jogar sem intervenção humana.  </li>
</ul>
<h3 id="32-veiculos-autonomos"><strong>3.2 Veículos Autônomos</strong></h3>
<ul>
<li>Controlar <strong>carros autônomos</strong> para aprender a dirigir de maneira eficiente.  </li>
<li>Otimizar trajetórias para evitar obstáculos e minimizar tempo de viagem.  </li>
</ul>
<h3 id="33-robotica"><strong>3.3 Robótica</strong></h3>
<ul>
<li>Ensinar <strong>braços robóticos</strong> a executar tarefas sem precisar de programação explícita.  </li>
<li>Desenvolver drones que aprendem a navegar por diferentes ambientes.  </li>
</ul>
<h3 id="34-financas-e-comercio-eletronico"><strong>3.4 Finanças e Comércio Eletrônico</strong></h3>
<ul>
<li>Criar <strong>estratégias de negociação automatizadas</strong> em mercados financeiros.  </li>
<li>Melhorar recomendações de produtos para consumidores em lojas virtuais.  </li>
</ul>
<hr />
<h2 id="vantagens-e-desafios-do-q-learning"><strong>Vantagens e Desafios do Q-Learning</strong></h2>
<h3 id="41-vantagens"><strong>4.1 Vantagens</strong></h3>
<p><strong>Aprendizado sem supervisão</strong>: não precisa de dados rotulados, aprende por tentativa e erro.<br />
<strong>Adaptabilidade</strong>: pode ser aplicado a diferentes tipos de problemas e ambientes.<br />
<strong>Exploração de soluções inovadoras</strong>: pode encontrar estratégias que não seriam intuitivas para humanos.  </p>
<h3 id="42-desafios"><strong>4.2 Desafios</strong></h3>
<p><strong>Tempo de convergência</strong>: pode levar muitas iterações para aprender a melhor estratégia.<br />
<strong>Problemas com grandes espaços de estados</strong>: se o número de estados e ações for muito grande, a Q-table pode se tornar <strong>impraticável</strong>.<br />
<strong>Exploração vs. Exploração</strong>: o equilíbrio entre testar novas ações e usar o conhecimento já adquirido pode ser difícil de ajustar.  </p>
<p>Para resolver alguns desses problemas, variações do Q-Learning foram desenvolvidas, como o <strong>Deep Q-Networks (DQN)</strong>, que utiliza redes neurais para lidar com espaços de estado muito grandes.  </p>
<h1 id="classificacao-e-regressao-no-aprendizado-de-maquina"><strong>Classificação e Regressão no Aprendizado de Máquina</strong></h1>
<p>No contexto do aprendizado de máquina, <strong>classificação</strong> e <strong>regressão</strong> são duas abordagens fundamentais utilizadas para fazer previsões a partir de dados históricos. Ambos os métodos fazem parte do <strong>aprendizado supervisionado</strong>, onde o modelo é treinado com um conjunto de dados rotulado antes de fazer previsões sobre novos dados.  </p>
<h3 id="classificacao"><strong>Classificação</strong></h3>
<p>A classificação é usada quando o objetivo do modelo é prever rótulos discretos ou categorias. Exemplos comuns incluem:<br />
- <strong>Detecção de e-mails spam</strong> (spam ou não spam).<br />
- <strong>Diagnóstico médico</strong> (doente ou saudável).<br />
- <strong>Reconhecimento de imagens</strong> (identificação de objetos, rostos, etc.).  </p>
<p>Os algoritmos de classificação tentam encontrar padrões que separam diferentes categorias dentro dos dados. Entre os algoritmos populares estão <strong>K-Nearest Neighbors (KNN)</strong>, <strong>Árvores de Decisão</strong>, <strong>Máquinas de Vetores de Suporte (SVM)</strong> e <strong>Redes Neurais</strong>.  </p>
<h3 id="regressao"><strong>Regressão</strong></h3>
<p>A regressão, por outro lado, é utilizada quando a variável de saída é contínua, ou seja, assume valores numéricos. Exemplos incluem:<br />
- <strong>Previsão de preços de imóveis</strong> com base em tamanho e localização.<br />
- <strong>Estimativa de temperatura</strong> para os próximos dias.<br />
- <strong>Cálculo de vendas futuras</strong> de um produto.  </p>
<p>Os algoritmos de regressão buscam modelar a relação entre as variáveis independentes e a variável dependente. Alguns dos algoritmos mais comuns incluem <strong>Regressão Linear</strong>, <strong>Regressão Polinomial</strong> e <strong>Redes Neurais para séries temporais</strong>.  </p>
<p><strong>i. Extração de Características</strong><br />
Antes de treinar um modelo, é essencial <strong>extrair características</strong> relevantes dos dados brutos. Características são informações extraídas dos dados que ajudam o modelo a tomar decisões precisas.  </p>
<p><strong>Métodos de Extração de Características:</strong><br />
1. <strong>Seleção de atributos</strong> – Escolher apenas as variáveis mais relevantes para evitar ruído nos dados.<br />
2. <strong>Transformação de dados</strong> – Como converter imagens em números ou palavras em vetores para modelos de NLP.<br />
3. <strong>Redução de dimensionalidade</strong> – Técnicas como PCA (Principal Component Analysis) ajudam a reduzir a quantidade de características mantendo a informação essencial.  </p>
<p>Por exemplo, em um modelo de reconhecimento de rostos, ao invés de usar a imagem bruta, características como <strong>distância entre olhos e boca, formato do nariz e contorno do rosto</strong> podem ser extraídas e utilizadas para classificar indivíduos corretamente.  </p>
<p><strong>ii. Pré-processamento de Dados</strong><br />
O pré-processamento dos dados é uma etapa crucial para garantir que os modelos de aprendizado de máquina funcionem corretamente. Dados brutos geralmente contêm <strong>ruídos, valores ausentes e formatos inconsistentes</strong>, que precisam ser tratados antes do treinamento.  </p>
<p><strong>Principais Técnicas de Pré-processamento:</strong><br />
1. <strong>Normalização e Padronização</strong> – Transformar os dados para uma escala comum, especialmente útil para algoritmos como Redes Neurais e SVM.<br />
2. <strong>Tratamento de valores ausentes</strong> – Substituir valores ausentes por médias, medianas ou usar técnicas como interpolação.<br />
3. <strong>Codificação de variáveis categóricas</strong> – Converter categorias textuais em valores numéricos usando técnicas como One-Hot Encoding.<br />
4. <strong>Remoção de outliers</strong> – Identificar e eliminar pontos extremos que possam distorcer o modelo.  </p>
<p>Por exemplo, se estivermos trabalhando com um modelo de previsão de preços de imóveis, podemos precisar converter características como "bairro" em números e normalizar valores como "área do imóvel" para que todas as variáveis tenham um impacto equilibrado na previsão.  </p>
<p><strong>iii. Overfitting e Underfitting</strong><br />
Ao treinar um modelo, um dos maiores desafios é encontrar o equilíbrio entre <strong>overfitting (sobreajuste)</strong> e <strong>underfitting (subajuste)</strong>.  </p>
<p><strong>Overfitting (Sobreajuste)</strong><br />
Ocorre quando um modelo se ajusta excessivamente aos dados de treinamento, aprendendo detalhes e ruídos que não são generalizáveis para novos dados. Isso leva a um excelente desempenho no conjunto de treinamento, mas um fraco desempenho no mundo real.  </p>
<p><strong>Como evitar overfitting?</strong><br />
- <strong>Aumentar os dados</strong> (Data Augmentation).<br />
- <strong>Regularização</strong> (L1/L2, dropout em redes neurais).<br />
- <strong>Reduzir a complexidade do modelo</strong> (menos camadas, menos parâmetros).<br />
- <strong>Usar validação cruzada</strong> para garantir que o modelo generalize bem.  </p>
<p><strong>Underfitting (Subajuste)</strong><br />
Ocorre quando o modelo é muito simples para capturar os padrões dos dados, resultando em baixa precisão tanto no treinamento quanto nos testes.  </p>
<p><strong>Como evitar underfitting?</strong><br />
- <strong>Aumentar a complexidade do modelo</strong> (usar mais camadas em redes neurais, adicionar mais termos na regressão).<br />
- <strong>Fornecer mais dados de treinamento</strong> se o dataset for pequeno.<br />
- <strong>Treinar por mais tempo</strong> para permitir que o modelo aprenda corretamente.  </p>
<p>Uma boa prática para evitar ambos os problemas é dividir os dados em <strong>treinamento, validação e teste</strong>, garantindo que o modelo não memorize os dados de treino e generalize bem para novos exemplos.  </p>
<p><strong>Conclusão</strong><br />
Classificação e regressão são abordagens essenciais dentro do aprendizado de máquina, aplicadas a uma variedade de problemas do mundo real. No entanto, para obter modelos eficazes, é necessário realizar um bom pré-processamento dos dados, escolher características relevantes e evitar os desafios de <strong>overfitting</strong> e <strong>underfitting</strong>.  </p>
<hr />
<h1 id="redes-neurais-e-aprendizado-profundo"><strong>Redes Neurais e Aprendizado Profundo</strong></h1>
<p>O avanço da inteligência artificial nas últimas décadas foi impulsionado pelo desenvolvimento de <strong>redes neurais artificiais (RNAs)</strong> e técnicas de <strong>aprendizado profundo (deep learning)</strong>. Esses métodos são inspirados no funcionamento do cérebro humano e permitem que máquinas realizem tarefas complexas, como <strong>reconhecimento de imagens, tradução automática e geração de texto</strong>.  </p>
<h2 id="1-redes-neurais-artificiais-rnas"><strong>1. Redes Neurais Artificiais (RNAs)</strong></h2>
<p>As <strong>redes neurais artificiais</strong> são modelos computacionais que simulam o funcionamento de neurônios biológicos. Elas são compostas por unidades chamadas <strong>neurônios artificiais</strong>, que realizam cálculos matemáticos para aprender padrões a partir dos dados.  </p>
<h3 id="11-estrutura-de-uma-rede-neural"><strong>1.1 Estrutura de uma Rede Neural</strong></h3>
<p>Uma rede neural típica é organizada em <strong>camadas</strong>:<br />
- <strong>Camada de entrada:</strong> recebe os dados brutos, como pixels de uma imagem ou palavras de um texto.<br />
- <strong>Camadas ocultas:</strong> realizam transformações matemáticas para extrair padrões dos dados.<br />
- <strong>Camada de saída:</strong> produz a previsão final, como a categoria de um objeto em uma imagem.  </p>
<p>Cada neurônio realiza um cálculo matemático simples:  </p>
<div class="arithmatex">\[
Y = f(WX + b)
\]</div>
<p>Onde:<br />
- <strong><span class="arithmatex">\( W \)</span></strong> são os pesos aprendidos pelo modelo.<br />
- <strong><span class="arithmatex">\( X \)</span></strong> são os dados de entrada.<br />
- <strong><span class="arithmatex">\( b \)</span></strong> é um termo de viés.<br />
- <strong><span class="arithmatex">\( f \)</span></strong> é uma função de ativação, como ReLU ou sigmoide.  </p>
<hr />
<h2 id="2-aprendizado-profundo-deep-learning"><strong>2. Aprendizado Profundo (Deep Learning)</strong></h2>
<p>O aprendizado profundo é uma subárea das redes neurais que utiliza <strong>múltiplas camadas ocultas</strong> para aprender representações complexas dos dados. Diferente dos modelos tradicionais de aprendizado de máquina, que exigem <strong>engenharia de características manual</strong>, redes profundas aprendem automaticamente as melhores representações dos dados.  </p>
<h3 id="21-por-que-o-deep-learning-e-poderoso"><strong>2.1 Por que o Deep Learning é poderoso?</strong></h3>
<ul>
<li><strong>Maior capacidade de aprendizado:</strong> redes profundas podem modelar relações complexas.  </li>
<li><strong>Eliminação da engenharia manual de características:</strong> o modelo aprende automaticamente representações úteis.  </li>
<li><strong>Aproveitamento do grande volume de dados e do poder computacional atual:</strong> GPUs e TPUs permitem treinar redes muito grandes.  </li>
</ul>
<h3 id="22-principais-arquiteturas-de-redes-neurais-profundas"><strong>2.2 Principais Arquiteturas de Redes Neurais Profundas</strong></h3>
<p>O aprendizado profundo evoluiu e deu origem a diferentes tipos de redes neurais, cada uma otimizada para um tipo específico de problema.  </p>
<h4 id="221-redes-neurais-convolucionais-cnns-convolutional-neural-networks"><strong>2.2.1 Redes Neurais Convolucionais (CNNs - Convolutional Neural Networks)</strong></h4>
<ul>
<li>Especializadas em <strong>processamento de imagens</strong>.  </li>
<li>Utilizam <strong>filtros convolucionais</strong> para extrair características como bordas e texturas.  </li>
<li>Aplicações: reconhecimento facial, detecção de objetos, diagnósticos médicos em imagens.  </li>
</ul>
<h4 id="222-redes-neurais-recorrentes-rnns-recurrent-neural-networks"><strong>2.2.2 Redes Neurais Recorrentes (RNNs - Recurrent Neural Networks)</strong></h4>
<ul>
<li>Projetadas para <strong>dados sequenciais</strong>, como texto e séries temporais.  </li>
<li>Possuem <strong>memória</strong> para armazenar informações anteriores e entender contexto.  </li>
<li>Aplicações: tradução automática, reconhecimento de fala, previsões financeiras.  </li>
</ul>
<h4 id="223-redes-transformers"><strong>2.2.3 Redes Transformers</strong></h4>
<ul>
<li>Utilizam o <strong>mecanismo de atenção</strong>, permitindo processar informações de maneira eficiente.  </li>
<li>São a base de modelos como o <strong>GPT (Generative Pre-trained Transformer)</strong> e <strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>.  </li>
<li>Aplicações: geração de texto, chatbots, assistentes virtuais.  </li>
</ul>
<hr />
<h2 id="3-treinamento-de-redes-neurais"><strong>3. Treinamento de Redes Neurais</strong></h2>
<p>O treinamento de uma rede neural envolve ajustar os <strong>pesos <span class="arithmatex">\( W \)</span></strong> e o <strong>viés <span class="arithmatex">\( b \)</span></strong> para minimizar o erro entre as previsões e os valores reais. Esse processo é feito por meio de <strong>gradiente descendente e backpropagation</strong>:  </p>
<ol>
<li><strong>Propagação direta (Forward Pass):</strong> os dados passam pela rede e geram uma previsão.  </li>
<li><strong>Cálculo do erro (Loss Function):</strong> mede a diferença entre a previsão e o valor real.  </li>
<li><strong>Backpropagation:</strong> o erro é propagado de volta para ajustar os pesos.  </li>
<li><strong>Otimização (Gradient Descent):</strong> ajusta os pesos para minimizar o erro.  </li>
</ol>
<h3 id="31-funcoes-de-ativacao"><strong>3.1 Funções de Ativação</strong></h3>
<p>As redes neurais utilizam funções de ativação para introduzir <strong>não linearidade</strong> nos cálculos, permitindo que aprendam padrões mais complexos. Algumas das principais funções de ativação são:<br />
- <strong>ReLU (Rectified Linear Unit):</strong> usada em CNNs para imagens.<br />
- <strong>Sigmoide:</strong> útil para classificações binárias.<br />
- <strong>Softmax:</strong> utilizada para problemas de classificação multiclasse.  </p>
<hr />
<h2 id="4-desafios-das-redes-neurais-e-do-deep-learning"><strong>4. Desafios das Redes Neurais e do Deep Learning</strong></h2>
<p>Apesar de seu sucesso, redes neurais profundas possuem desafios importantes:  </p>
<h3 id="41-overfitting-sobreajuste"><strong>4.1 Overfitting (Sobreajuste)</strong></h3>
<ul>
<li>Redes profundas podem <strong>memorizar</strong> os dados de treinamento, prejudicando a generalização para novos dados.  </li>
<li><strong>Solução:</strong> técnicas como dropout, aumento de dados e regularização.  </li>
</ul>
<h3 id="42-alto-custo-computacional"><strong>4.2 Alto Custo Computacional</strong></h3>
<ul>
<li>Treinar modelos profundos requer <strong>grandes quantidades de dados e poder computacional</strong> (GPUs e TPUs são frequentemente usadas).  </li>
<li><strong>Solução:</strong> técnicas como redes pré-treinadas e aprendizado transferido.  </li>
</ul>
<h3 id="43-explicabilidade-xai-explainable-ai"><strong>4.3 Explicabilidade (XAI - Explainable AI)</strong></h3>
<ul>
<li>Modelos de deep learning são frequentemente chamados de <strong>"caixas-pretas"</strong>, pois não é fácil entender como tomam decisões.  </li>
<li><strong>Solução:</strong> métodos como Grad-CAM e LIME tentam explicar as decisões dos modelos.  </li>
</ul>
<hr />
<h2 id="5-aplicacoes-do-deep-learning-no-mundo-real"><strong>5. Aplicações do Deep Learning no Mundo Real</strong></h2>
<h3 id="51-visao-computacional"><strong>5.1 Visão Computacional</strong></h3>
<ul>
<li><strong>Reconhecimento facial (ex.: desbloqueio de celulares).</strong>  </li>
<li><strong>Detecção de doenças em exames médicos.</strong>  </li>
<li><strong>Carros autônomos (identificação de sinais e pedestres).</strong>  </li>
</ul>
<h3 id="52-processamento-de-linguagem-natural-nlp"><strong>5.2 Processamento de Linguagem Natural (NLP)</strong></h3>
<ul>
<li><strong>Tradução automática (ex.: Google Translate).</strong>  </li>
<li><strong>Chatbots e assistentes virtuais (ex.: ChatGPT, Alexa, Siri).</strong>  </li>
<li><strong>Análise de sentimentos em redes sociais.</strong>  </li>
</ul>
<h3 id="53-jogos-e-simulacoes"><strong>5.3 Jogos e Simulações</strong></h3>
<ul>
<li><strong>Redes neurais foram usadas para criar a AlphaGo, que venceu campeões humanos no jogo Go.</strong>  </li>
<li><strong>Simulações complexas, como previsão do clima e modelagem molecular.</strong>  </li>
</ul>
<hr />
<h2 id="conclusao_1"><strong>Conclusão</strong></h2>
<p>As redes neurais artificiais e o aprendizado profundo revolucionaram a inteligência artificial, permitindo avanços impressionantes em <strong>visão computacional, linguagem natural e diversas outras áreas</strong>. No entanto, ainda existem desafios como <strong>overfitting, alto custo computacional e falta de interpretabilidade</strong>, que continuam sendo explorados pela comunidade científica.  </p>
<h1 id="explainable-artificial-intelligence-xai-inteligencia-artificial-explicavel"><strong>Explainable Artificial Intelligence (XAI) – Inteligência Artificial Explicável</strong></h1>
<p>A Inteligência Artificial (IA) tem se tornado uma ferramenta essencial em diversas áreas, desde diagnósticos médicos até decisões financeiras e veículos autônomos. No entanto, muitos dos modelos de <strong>aprendizado profundo (Deep Learning)</strong> e <strong>aprendizado de máquina (Machine Learning)</strong> são considerados <strong>"caixas-pretas"</strong>, ou seja, suas decisões são difíceis de interpretar.  </p>
<p>A <strong>Inteligência Artificial Explicável (XAI – Explainable Artificial Intelligence)</strong> surgiu como um campo de pesquisa que busca <strong>tornar os modelos de IA mais transparentes, interpretáveis e confiáveis</strong>. O objetivo é fornecer justificativas claras para as previsões dos modelos, garantindo maior confiança e responsabilidade no uso da IA.  </p>
<hr />
<h2 id="1-por-que-a-ia-explicavel-e-necessaria"><strong>1. Por que a IA Explicável é Necessária?</strong></h2>
<p>À medida que a IA é aplicada em <strong>áreas críticas</strong>, como <strong>saúde, segurança e justiça</strong>, torna-se fundamental entender como ela toma suas decisões. Algumas razões para isso incluem:  </p>
<h3 id="11-confiabilidade-e-transparencia"><strong>1.1 Confiabilidade e Transparência</strong></h3>
<ul>
<li>Usuários e especialistas precisam confiar nos sistemas de IA.  </li>
<li>Empresas e organizações precisam garantir que as decisões tomadas por IA sejam <strong>compreensíveis e auditáveis</strong>.  </li>
</ul>
<h3 id="12-etica-e-justica"><strong>1.2 Ética e Justiça</strong></h3>
<ul>
<li>Modelos de IA podem refletir <strong>viés nos dados</strong>, levando a decisões injustas.  </li>
<li>Exemplo: um sistema de recrutamento baseado em IA pode favorecer certos grupos sociais devido a <strong>dados históricos enviesados</strong>.  </li>
</ul>
<h3 id="13-regulamentacoes-e-conformidade"><strong>1.3 Regulamentações e Conformidade</strong></h3>
<ul>
<li>Leis como o <strong>GDPR (Regulamento Geral de Proteção de Dados da União Europeia)</strong> exigem que as organizações expliquem decisões automatizadas.  </li>
<li>Setores como <strong>finanças e saúde</strong> precisam justificar decisões para evitar <strong>riscos legais</strong>.  </li>
</ul>
<h3 id="14-depuracao-e-melhoria-de-modelos"><strong>1.4 Depuração e Melhoria de Modelos</strong></h3>
<ul>
<li><strong>Engenheiros de IA precisam entender os erros dos modelos para melhorá-los</strong>.  </li>
<li>Com explicabilidade, é possível identificar <strong>falhas e viés no treinamento</strong>.  </li>
</ul>
<hr />
<h2 id="2-tipos-de-explicabilidade-em-ia"><strong>2. Tipos de Explicabilidade em IA</strong></h2>
<p>A explicabilidade pode ser abordada de diferentes maneiras:  </p>
<h3 id="21-explicabilidade-global-vs-local"><strong>2.1 Explicabilidade Global vs. Local</strong></h3>
<ul>
<li><strong>Explicabilidade Global:</strong> compreende o modelo inteiro, identificando quais recursos influenciam mais suas decisões.  </li>
<li><strong>Explicabilidade Local:</strong> foca em explicar uma decisão específica do modelo para um dado individual.  </li>
</ul>
<h3 id="22-modelos-interpretabis-vs-modelos-caixa-preta"><strong>2.2 Modelos Interpretabis vs. Modelos Caixa-Preta</strong></h3>
<ul>
<li><strong>Modelos Interpretáveis:</strong> métodos mais simples, como <strong>árvores de decisão</strong> e <strong>regressões lineares</strong>, onde os cálculos são diretos e compreensíveis.  </li>
<li><strong>Modelos Caixa-Preta:</strong> redes neurais profundas e algoritmos complexos, que precisam de técnicas especiais para interpretação.  </li>
</ul>
<hr />
<h2 id="3-metodos-de-explicabilidade-em-ia"><strong>3. Métodos de Explicabilidade em IA</strong></h2>
<p>Para entender como os modelos de IA tomam decisões, diversas técnicas foram desenvolvidas.  </p>
<h3 id="31-shap-shapley-additive-explanations"><strong>3.1 SHAP (Shapley Additive Explanations)</strong></h3>
<ul>
<li>Baseado na <strong>teoria dos jogos</strong>, mede a contribuição de cada variável na decisão final do modelo.  </li>
<li>Ajuda a entender <strong>quanto cada característica influenciou a previsão</strong>.  </li>
</ul>
<h3 id="32-lime-local-interpretable-model-agnostic-explanations"><strong>3.2 LIME (Local Interpretable Model-Agnostic Explanations)</strong></h3>
<ul>
<li>Cria <strong>modelos mais simples</strong> ao redor de uma predição específica para entender quais variáveis influenciaram a decisão.  </li>
<li>Funciona bem com redes neurais e outros modelos complexos.  </li>
</ul>
<h3 id="33-grad-cam-gradient-weighted-class-activation-mapping"><strong>3.3 Grad-CAM (Gradient-weighted Class Activation Mapping)</strong></h3>
<ul>
<li>Utilizado em <strong>redes neurais convolucionais (CNNs)</strong> para visão computacional.  </li>
<li>Gera <strong>mapas de calor</strong> para mostrar quais partes da imagem influenciaram a decisão do modelo.  </li>
</ul>
<h3 id="34-feature-importance-importancia-das-caracteristicas"><strong>3.4 Feature Importance (Importância das Características)</strong></h3>
<ul>
<li>Determina <strong>quais variáveis</strong> tiveram maior impacto nas previsões.  </li>
<li>Pode ser calculado diretamente para modelos como <strong>árvores de decisão</strong> e <strong>florestas aleatórias</strong>.  </li>
</ul>
<hr />
<h2 id="4-aplicacoes-da-xai"><strong>4. Aplicações da XAI</strong></h2>
<p>A IA Explicável está sendo aplicada em diversos setores para garantir decisões mais transparentes e confiáveis.  </p>
<h3 id="41-saude"><strong>4.1 Saúde</strong></h3>
<ul>
<li><strong>Diagnósticos médicos</strong>: explicar por que um modelo previu uma doença em um paciente.  </li>
<li><strong>Pesquisa farmacêutica</strong>: entender quais fatores influenciam a descoberta de novos medicamentos.  </li>
</ul>
<h3 id="42-financas"><strong>4.2 Finanças</strong></h3>
<ul>
<li><strong>Aprovação de crédito</strong>: justificar por que um cliente recebeu ou não um empréstimo.  </li>
<li><strong>Detecção de fraudes</strong>: indicar quais padrões levaram a uma transação ser considerada suspeita.  </li>
</ul>
<h3 id="43-seguranca-e-justica"><strong>4.3 Segurança e Justiça</strong></h3>
<ul>
<li><strong>Reconhecimento facial</strong>: garantir que o modelo não tenha viés racial ou de gênero.  </li>
<li><strong>Sistemas de recomendação</strong>: explicar por que um usuário recebeu certas sugestões em plataformas online.  </li>
</ul>
<hr />
<h2 id="5-desafios-da-xai"><strong>5. Desafios da XAI</strong></h2>
<p>Apesar dos avanços, a implementação da IA Explicável ainda enfrenta desafios importantes:  </p>
<h3 id="51-complexidade-dos-modelos"><strong>5.1 Complexidade dos Modelos</strong></h3>
<ul>
<li>Redes neurais profundas possuem milhões de parâmetros, tornando difícil interpretar suas decisões.  </li>
<li>Algumas técnicas de explicabilidade podem simplificar <strong>excessivamente</strong> os resultados, levando a explicações imprecisas.  </li>
</ul>
<h3 id="52-vies-nos-dados-e-no-processo-de-explicacao"><strong>5.2 Viés nos Dados e no Processo de Explicação</strong></h3>
<ul>
<li>Se os dados de treinamento forem enviesados, o modelo poderá reforçar esse viés.  </li>
<li>Mesmo métodos de XAI podem ser manipulados para dar explicações <strong>parciais ou enganosas</strong>.  </li>
</ul>
<h3 id="53-equilibrio-entre-precisao-e-explicabilidade"><strong>5.3 Equilíbrio entre Precisão e Explicabilidade</strong></h3>
<ul>
<li>Muitas vezes, modelos mais interpretáveis são menos precisos do que modelos complexos de aprendizado profundo.  </li>
<li>Encontrar um <strong>equilíbrio</strong> entre interpretabilidade e desempenho é um grande desafio.  </li>
</ul>
<hr />
<h2 id="6-o-futuro-da-ia-explicavel"><strong>6. O Futuro da IA Explicável</strong></h2>
<p>O campo da XAI continua evoluindo, com novas técnicas sendo desenvolvidas para tornar a IA mais transparente e justa. Algumas tendências incluem:  </p>
<ul>
<li><strong>Modelos mais interpretáveis desde o início</strong> (em vez de apenas tentar explicar modelos já treinados).  </li>
<li><strong>Integração de XAI em regulamentações</strong> para tornar decisões de IA mais auditáveis.  </li>
<li><strong>Desenvolvimento de novas ferramentas de visualização</strong> para facilitar a interpretação dos modelos.  </li>
</ul>
<p>À medida que a IA se torna mais presente no nosso cotidiano, a <strong>explicabilidade será essencial para garantir seu uso responsável e ético</strong>.  </p>
<hr />
<h2 id="conclusao_2"><strong>Conclusão</strong></h2>
<p>A Inteligência Artificial Explicável (XAI) é um campo crucial para garantir que os modelos de IA sejam <strong>transparentes, confiáveis e justos</strong>. Com o uso de técnicas como <strong>SHAP, LIME e Grad-CAM</strong>, é possível entender melhor como os modelos tomam decisões e corrigir possíveis falhas ou vieses.  </p>
<hr />
<h1 id="referencias-bibliograficas">Referências bibliográficas</h1>
<ol>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press.</li>
<li>Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement Learning: An Introduction</em>. MIT Press.</li>
<li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer.</li>
<li>Mitchell, T. M. (1997). <em>Machine Learning</em>. McGraw-Hill.</li>
<li>Shalev-Shwartz, S., &amp; Ben-David, S. (2014). <em>Understanding Machine Learning: From Theory to Algorithms</em>. Cambridge University Press.</li>
<li>Chollet, F. (2018). <em>Deep Learning with Python</em>. Manning Publications.</li>
<li>Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016). "Why should I trust you?" Explaining the predictions of any classifier. <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>.</li>
<li>Xu, R., &amp; Wunsch, D. (2005). <em>Clustering</em>. Wiley-Interscience.</li>
<li>Kohonen, T. (2001). <em>Self-Organizing Maps</em>. Springer.</li>
<li>MacKay, D. J. C. (2003). <em>Information Theory, Inference, and Learning Algorithms</em>. Cambridge University Press.</li>
<li>Zhang, X., &amp; Chen, L. (2020). "A Comprehensive Review on Deep Reinforcement Learning." <em>Neural Networks</em>.</li>
<li>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). "ImageNet Classification with Deep Convolutional Neural Networks." <em>Neural Information Processing Systems (NeurIPS)</em>.</li>
<li>Koller, D., &amp; Friedman, N. (2009). <em>Probabilistic Graphical Models: Principles and Techniques</em>. MIT Press.</li>
</ol>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": ".", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>